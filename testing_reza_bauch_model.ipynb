{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4381a83c-a6a2-42aa-9d41-85ec19f33a61",
   "metadata": {},
   "source": [
    "### test reza and bauch - bauch test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1894ea1-28fd-4def-ab33-c35c659d7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# load the data\n",
    "with open(\"preproccessed_data_uncensored.pickle\", \"rb\") as f:\n",
    "    data_dic = pickle.load(f)\n",
    "\n",
    "test = data_dic['test']\n",
    "test_target = data_dic['test_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776fa1f5-032a-416b-9740-3e9ede7715ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bauch_apply_bauch_test_uncen.pickle\", \"rb\") as f:\n",
    "    test_preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a1a11d-91be-4541-8fca-a66db8511c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd257c0-e953-47e5-8c7b-66568d8146a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test)\n",
    "test_target = np.array(test_target)\n",
    "\n",
    "filter_list = [t>1 for t in test_target]\n",
    "test = test[filter_list]\n",
    "test_target = test_target[filter_list]\n",
    "\n",
    "# test_target[test_target == 3] = 0\n",
    "# test_target[test_target == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbaaf297-a48c-42b3-8abb-7dfbc19bfcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.array(test_preds)\n",
    "test_preds = test_preds[filter_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee1982-0281-4704-95c4-9241e9adc21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42bf14eb-52cf-4822-9b57-2e465e189527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2      0.493     0.972     0.654       500\n",
      "           3      0.000     0.000     0.000       500\n",
      "\n",
      "    accuracy                          0.486      1000\n",
      "   macro avg      0.246     0.486     0.327      1000\n",
      "weighted avg      0.246     0.486     0.327      1000\n",
      "\n",
      "F1 score: 0.32705248990578734\n",
      "Precision:  0.24645030425963488\n",
      "Recall:  0.486\n",
      "Confusion matrix: \n",
      " [[486  14]\n",
      " [500   0]]\n"
     ]
    }
   ],
   "source": [
    "#performance on bauch uncensored\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_preds = np.argmax(test_preds, axis=2)\n",
    "# test_preds[test_preds == 3] = 0\n",
    "# test_preds[test_preds == 2] = 1\n",
    "print(\"accuracy: \", accuracy_score(test_target, test_preds))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(classification_report(test_target, test_preds, digits=3))\n",
    "print(\"F1 score:\",f1_score(test_target, test_preds, average='macro'))\n",
    "print(\"Precision: \",precision_score(test_target, test_preds, average=\"macro\"))\n",
    "print(\"Recall: \",recall_score(test_target, test_preds, average=\"macro\"))    \n",
    "print(\"Confusion matrix: \\n\",confusion_matrix(test_target, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfb41b1b-fc49-4fbc-8916-cc38ae925640",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reza_apply_bauch_test_uncen.pickle\", \"rb\") as f:\n",
    "    test_preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21543b75-64ea-4462-b8e4-ffd117af5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.array(test_preds)\n",
    "test_preds = test_preds[filter_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8dab4e0c-ecf5-418c-bdb3-bccc60f45ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00454521],\n",
       "       [-0.01702688],\n",
       "       [-0.01614218],\n",
       "       ...,\n",
       "       [-0.00547889],\n",
       "       [ 0.00033639],\n",
       "       [-0.00284049]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31258ada-1a43-44ee-94f3-01f288cfe008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       500\n",
      "           1      0.500     1.000     0.667       500\n",
      "\n",
      "    accuracy                          0.500      1000\n",
      "   macro avg      0.250     0.500     0.333      1000\n",
      "weighted avg      0.250     0.500     0.333      1000\n",
      "\n",
      "F1 score: 0.3333333333333333\n",
      "Precision:  0.25\n",
      "Recall:  0.5\n",
      "Confusion matrix: \n",
      " [[  0 500]\n",
      " [  0 500]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#performance on bauch uncensored\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_preds = np.argmax(test_preds, axis=2)\n",
    "# test_preds[test_preds == 3] = 0\n",
    "# test_preds[test_preds == 2] = 1\n",
    "print(\"accuracy: \", accuracy_score(test_target, test_preds))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(classification_report(test_target, test_preds, digits=3))\n",
    "print(\"F1 score:\",f1_score(test_target, test_preds, average='macro'))\n",
    "print(\"Precision: \",precision_score(test_target, test_preds, average=\"macro\"))\n",
    "print(\"Recall: \",recall_score(test_target, test_preds, average=\"macro\"))    \n",
    "print(\"Confusion matrix: \\n\",confusion_matrix(test_target, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb61840-970d-41d5-8fed-55242497c375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a8d51b0-96f7-4823-9132-6561d038d658",
   "metadata": {},
   "source": [
    "### test noise induced - reza and bauch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ca5c9d-1b34-4507-bdb6-edb2e945b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"train_amit/envn_uncen_resids_dic.pickle\", \"rb\") as f:\n",
    "    data_dic_t1 = pickle.load(f)\n",
    "\n",
    "with open(\"train_amit/whiten_uncen_resids_dic.pickle\", \"rb\") as f:\n",
    "    data_dic_t2 = pickle.load(f)\n",
    "\n",
    "with open(\"train_amit/demn_uncen_resids_dic.pickle\", \"rb\") as f:\n",
    "    data_dic_t3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a57411-7da5-4979-9f78-a1c59cf0dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_envn = data_dic_t1['test']\n",
    "test_envn_target = data_dic_t1['test_target']\n",
    "test_whiten = data_dic_t2['test']\n",
    "test_whiten_target = data_dic_t2['test_target']\n",
    "test_demn = data_dic_t3['test']\n",
    "test_demn_target = data_dic_t3['test_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd7a9ff-9d3e-487b-9521-77dff9e3f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"reza_apply_test_demn_uncen.pickle\", \"rb\") as f:\n",
    "    preds_demn = pickle.load(f)\n",
    "\n",
    "with open(\"reza_apply_test_whiten_uncen.pickle\", \"rb\") as f:\n",
    "    preds_whiten = pickle.load(f)\n",
    "\n",
    "with open(\"reza_apply_test_envn_uncen.pickle\", \"rb\") as f:\n",
    "    preds_envn = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a508cdf8-b10b-42c4-a46e-d4b021999dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Env noise\n",
      "envn test accuracy:  0.996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     1.000     0.996       500\n",
      "           1      1.000     0.992     0.996       500\n",
      "\n",
      "    accuracy                          0.996      1000\n",
      "   macro avg      0.996     0.996     0.996      1000\n",
      "weighted avg      0.996     0.996     0.996      1000\n",
      "\n",
      "envn F1 score: 0.995999935998976\n",
      "envn Precision:  0.996031746031746\n",
      "envn Recall:  0.996\n",
      "envn Confusion matrix: \n",
      " [[500   0]\n",
      " [  4 496]]\n",
      "############### Dem noise\n",
      "demn test accuracy:  0.998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.998     0.998     0.998       500\n",
      "           1      0.998     0.998     0.998       500\n",
      "\n",
      "    accuracy                          0.998      1000\n",
      "   macro avg      0.998     0.998     0.998      1000\n",
      "weighted avg      0.998     0.998     0.998      1000\n",
      "\n",
      "envn F1 score: 0.998\n",
      "envn Precision:  0.998\n",
      "envn Recall:  0.998\n",
      "envn Confusion matrix: \n",
      " [[499   1]\n",
      " [  1 499]]\n",
      "############### White noise\n",
      "whiten test accuracy:  0.987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.978     0.987       500\n",
      "           1      0.978     0.996     0.987       500\n",
      "\n",
      "    accuracy                          0.987      1000\n",
      "   macro avg      0.987     0.987     0.987      1000\n",
      "weighted avg      0.987     0.987     0.987      1000\n",
      "\n",
      "whiten F1 score: 0.9869989469147\n",
      "whiten Precision:  0.9871578391398814\n",
      "whiten Recall:  0.987\n",
      "whiten Confusion matrix: \n",
      " [[489  11]\n",
      " [  2 498]]\n"
     ]
    }
   ],
   "source": [
    "# uncensored prerofmance\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "test_demn_preds = np.argmax(preds_demn, axis=2)\n",
    "test_whiten_preds = np.argmax(preds_whiten, axis=2)\n",
    "test_envn_preds = np.argmax(preds_envn, axis=2)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(\"############### Env noise\")\n",
    "print(\"envn test accuracy: \", accuracy_score(test_envn_target, test_envn_preds))\n",
    "print(classification_report(test_envn_target, test_envn_preds, digits=3))\n",
    "print(\"envn F1 score:\",f1_score(test_envn_target, test_envn_preds, average='macro'))\n",
    "print(\"envn Precision: \",precision_score(test_envn_target, test_envn_preds, average=\"macro\"))\n",
    "print(\"envn Recall: \",recall_score(test_envn_target, test_envn_preds, average=\"macro\"))    \n",
    "print(\"envn Confusion matrix: \\n\",confusion_matrix(test_envn_target, test_envn_preds))\n",
    "\n",
    "print(\"############### Dem noise\")\n",
    "print(\"demn test accuracy: \", accuracy_score(test_demn_target, test_demn_preds))\n",
    "print(classification_report(test_demn_target, test_demn_preds, digits=3))\n",
    "print(\"envn F1 score:\",f1_score(test_demn_target, test_demn_preds, average='macro'))\n",
    "print(\"envn Precision: \",precision_score(test_demn_target, test_demn_preds, average=\"macro\"))\n",
    "print(\"envn Recall: \",recall_score(test_demn_target, test_demn_preds, average=\"macro\"))    \n",
    "print(\"envn Confusion matrix: \\n\",confusion_matrix(test_demn_target, test_demn_preds))\n",
    "\n",
    "print(\"############### White noise\")\n",
    "print(\"whiten test accuracy: \", accuracy_score(test_whiten_target, test_whiten_preds))\n",
    "print(classification_report(test_whiten_target, test_whiten_preds, digits=3))\n",
    "print(\"whiten F1 score:\",f1_score(test_whiten_target, test_whiten_preds, average='macro'))\n",
    "print(\"whiten Precision: \",precision_score(test_whiten_target, test_whiten_preds, average=\"macro\"))\n",
    "print(\"whiten Recall: \",recall_score(test_whiten_target, test_whiten_preds, average=\"macro\"))    \n",
    "print(\"whiten Confusion matrix: \\n\",confusion_matrix(test_whiten_target, test_whiten_preds))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e328518-fa07-4f47-8db2-b46adf590817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"bauch_apply_test_demn_uncen.pickle\", \"rb\") as f:\n",
    "    preds_demn = pickle.load(f)\n",
    "\n",
    "with open(\"bauch_apply_test_whiten_uncen.pickle\", \"rb\") as f:\n",
    "    preds_whiten = pickle.load(f)\n",
    "\n",
    "with open(\"bauch_apply_test_envn_uncen.pickle\", \"rb\") as f:\n",
    "    preds_envn = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "058eca59-cbe8-4700-9490-8ae3e2a4cd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Env noise\n",
      "envn test accuracy:  0.752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.811     0.892     0.850       500\n",
      "           1      1.000     0.612     0.759       500\n",
      "           2      0.000     0.000     0.000         0\n",
      "           3      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.752      1000\n",
      "   macro avg      0.453     0.376     0.402      1000\n",
      "weighted avg      0.905     0.752     0.804      1000\n",
      "\n",
      "envn F1 score: 0.40220725511048094\n",
      "envn Precision:  0.45272727272727276\n",
      "envn Recall:  0.376\n",
      "envn Confusion matrix: \n",
      " [[446   0   6  48]\n",
      " [104 306  85   5]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n",
      "############### Dem noise\n",
      "demn test accuracy:  0.834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.900     0.812     0.854       500\n",
      "           1      1.000     0.856     0.922       500\n",
      "           2      0.000     0.000     0.000         0\n",
      "           3      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.834      1000\n",
      "   macro avg      0.475     0.417     0.444      1000\n",
      "weighted avg      0.950     0.834     0.888      1000\n",
      "\n",
      "envn F1 score: 0.4440629645744951\n",
      "envn Precision:  0.4750554323725056\n",
      "envn Recall:  0.41700000000000004\n",
      "envn Confusion matrix: \n",
      " [[406   0   0  94]\n",
      " [ 45 428  27   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n",
      "############### White noise\n",
      "whiten test accuracy:  0.649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.971     0.334     0.497       500\n",
      "           1      1.000     0.964     0.982       500\n",
      "           2      0.000     0.000     0.000         0\n",
      "           3      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.649      1000\n",
      "   macro avg      0.493     0.325     0.370      1000\n",
      "weighted avg      0.985     0.649     0.739      1000\n",
      "\n",
      "whiten F1 score: 0.3696734676559014\n",
      "whiten Precision:  0.49273255813953487\n",
      "whiten Recall:  0.3245\n",
      "whiten Confusion matrix: \n",
      " [[167   0   9 324]\n",
      " [  5 482  13   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rezmiry/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# uncensored prerofmance\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "test_demn_preds = np.argmax(preds_demn, axis=2)\n",
    "test_whiten_preds = np.argmax(preds_whiten, axis=2)\n",
    "test_envn_preds = np.argmax(preds_envn, axis=2)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(\"############### Env noise\")\n",
    "print(\"envn test accuracy: \", accuracy_score(test_envn_target, test_envn_preds))\n",
    "print(classification_report(test_envn_target, test_envn_preds, digits=3))\n",
    "print(\"envn F1 score:\",f1_score(test_envn_target, test_envn_preds, average='macro'))\n",
    "print(\"envn Precision: \",precision_score(test_envn_target, test_envn_preds, average=\"macro\"))\n",
    "print(\"envn Recall: \",recall_score(test_envn_target, test_envn_preds, average=\"macro\"))    \n",
    "print(\"envn Confusion matrix: \\n\",confusion_matrix(test_envn_target, test_envn_preds))\n",
    "\n",
    "print(\"############### Dem noise\")\n",
    "print(\"demn test accuracy: \", accuracy_score(test_demn_target, test_demn_preds))\n",
    "print(classification_report(test_demn_target, test_demn_preds, digits=3))\n",
    "print(\"envn F1 score:\",f1_score(test_demn_target, test_demn_preds, average='macro'))\n",
    "print(\"envn Precision: \",precision_score(test_demn_target, test_demn_preds, average=\"macro\"))\n",
    "print(\"envn Recall: \",recall_score(test_demn_target, test_demn_preds, average=\"macro\"))    \n",
    "print(\"envn Confusion matrix: \\n\",confusion_matrix(test_demn_target, test_demn_preds))\n",
    "\n",
    "print(\"############### White noise\")\n",
    "print(\"whiten test accuracy: \", accuracy_score(test_whiten_target, test_whiten_preds))\n",
    "print(classification_report(test_whiten_target, test_whiten_preds, digits=3))\n",
    "print(\"whiten F1 score:\",f1_score(test_whiten_target, test_whiten_preds, average='macro'))\n",
    "print(\"whiten Precision: \",precision_score(test_whiten_target, test_whiten_preds, average=\"macro\"))\n",
    "print(\"whiten Recall: \",recall_score(test_whiten_target, test_whiten_preds, average=\"macro\"))    \n",
    "print(\"whiten Confusion matrix: \\n\",confusion_matrix(test_whiten_target, test_whiten_preds))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ebebbc-17ce-40de-8d2b-d8aaf15568d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
