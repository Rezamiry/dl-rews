{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea4acda-36bf-4905-bd73-f2ab2b766545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 23:49:08.726837: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-14 23:49:09.305749: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 23:49:17.987117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    # TODO: Update docstrings\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output\n",
    "    \n",
    "\n",
    "class ClusterableWeightsCA(tfmot.clustering.keras.ClusteringAlgorithm):\n",
    "    \"\"\"This class provides a special lookup function for the the weights 'w'.\n",
    "    It reshapes and tile centroids the same way as the weights. This allows us\n",
    "    to find pulling indices efficiently.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_pulling_indices(self, weight):\n",
    "        clst_num = self.cluster_centroids.shape[0]\n",
    "        tiled_weights = tf.tile(tf.expand_dims(weight, axis=2), [1, 1, clst_num])\n",
    "        tiled_cluster_centroids = tf.tile(\n",
    "            tf.reshape(self.cluster_centroids, [1, 1, clst_num]),\n",
    "            [weight.shape[0], weight.shape[1], 1],\n",
    "        )\n",
    "\n",
    "        # We find the nearest cluster centroids and store them so that ops can build\n",
    "        # their kernels upon it\n",
    "        pulling_indices = tf.argmin(\n",
    "            tf.abs(tiled_weights - tiled_cluster_centroids), axis=2\n",
    "        )\n",
    "\n",
    "        return pulling_indices\n",
    "\n",
    "\n",
    "class PrunableClusterableLayer(\n",
    "    tf.keras.layers.Layer,\n",
    "    tfmot.sparsity.keras.PrunableLayer,\n",
    "    tfmot.clustering.keras.ClusterableLayer,\n",
    "):\n",
    "    def get_prunable_weights(self):\n",
    "        # Prune bias also, though that usually harms model accuracy too much.\n",
    "        return [(\"kernel\", self.kernel)]\n",
    "\n",
    "    def get_clusterable_weights(self):\n",
    "        # Cluster kernel and bias. This is just an example, clustering\n",
    "        # bias usually hurts model accuracy.\n",
    "        return [(\"kernel\", self.kernel), (\"bias\", self.bias)]\n",
    "\n",
    "    def get_clusterable_algorithm(self, weight_name):\n",
    "        \"\"\"Returns clustering algorithm for the custom weights 'w'.\"\"\"\n",
    "        if weight_name == \"kernel\":\n",
    "            return ClusterableWeightsCA\n",
    "        else:\n",
    "            # We don't cluster other weights.\n",
    "            return None\n",
    "\n",
    "\n",
    "class ConvEmbedding(PrunableClusterableLayer):\n",
    "    def __init__(self, num_filters, **kwargs):\n",
    "        super(ConvEmbedding, self).__init__(**kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.conv1d = layers.Conv1D(\n",
    "            filters=num_filters, kernel_size=1, activation=\"relu\"\n",
    "        )\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"num_filters\": self.num_filters,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedding = self.conv1d(inputs)\n",
    "\n",
    "        return embedding\n",
    "\n",
    "\n",
    "class PositionalEncoding(PrunableClusterableLayer):\n",
    "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(dtype=dtype, **kwargs)\n",
    "        self.max_steps = max_steps\n",
    "        self.max_dims = max_dims\n",
    "\n",
    "        if max_dims % 2 == 1:\n",
    "            max_dims += 1  # max_dims must be even\n",
    "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
    "        pos_emb = np.empty((1, max_steps, max_dims))\n",
    "        pos_emb[0, :, ::2] = np.sin(p / 10000 ** (2 * i / max_dims)).T\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10000 ** (2 * i / max_dims)).T\n",
    "        self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"max_steps\": self.max_steps,\n",
    "                \"max_dims\": self.max_dims,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs)\n",
    "        return inputs + self.positional_embedding[:, : shape[-2], : shape[-1]]\n",
    "\n",
    "\n",
    "class RelativePositionEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"Creates a positional embedding.\n",
    "\n",
    "    This layer calculates the position encoding as a mix of sine and cosine\n",
    "    functions with geometrically increasing wavelengths. Defined and formulized in\n",
    "    \"Attention is All You Need\", section 3.5.\n",
    "    (https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "    Arguments:\n",
    "    hidden_size: Size of the hidden layer.\n",
    "    min_timescale: Minimum scale that will be applied at each position\n",
    "    max_timescale: Maximum scale that will be applied at each position.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, min_timescale=1.0, max_timescale=1.0e4, **kwargs):\n",
    "        # We need to have a default dtype of float32, since the inputs (which Keras\n",
    "        # usually uses to infer the dtype) will always be int32.\n",
    "        # We compute the positional encoding in float32 even if the model uses\n",
    "        # float16, as many of the ops used, like log and exp, are numerically\n",
    "        # unstable in float16.\n",
    "        if \"dtype\" not in kwargs:\n",
    "            kwargs[\"dtype\"] = \"float32\"\n",
    "\n",
    "        super(RelativePositionEmbedding, self).__init__(**kwargs)\n",
    "        self._hidden_size = hidden_size\n",
    "        self._min_timescale = min_timescale\n",
    "        self._max_timescale = max_timescale\n",
    "\n",
    "    def call(self, inputs, length=None):\n",
    "        \"\"\"Implements call() for the layer.\n",
    "\n",
    "        Args:\n",
    "          inputs: An tensor whose second dimension will be used as `length`. If\n",
    "            `None`, the other `length` argument must be specified.\n",
    "          length: An optional integer specifying the number of positions. If both\n",
    "            `inputs` and `length` are spcified, `length` must be equal to the second\n",
    "            dimension of `inputs`.\n",
    "\n",
    "        Returns:\n",
    "          A tensor in shape of [length, hidden_size].\n",
    "        \"\"\"\n",
    "        shape = tf.shape(inputs)\n",
    "        length = shape[1]\n",
    "        position = tf.cast(tf.range(length), tf.float32)\n",
    "        num_timescales = self._hidden_size // 2\n",
    "        min_timescale, max_timescale = self._min_timescale, self._max_timescale\n",
    "        log_timescale_increment = math.log(\n",
    "            float(max_timescale) / float(min_timescale)\n",
    "        ) / (tf.cast(num_timescales, tf.float32) - 1)\n",
    "        inv_timescales = min_timescale * tf.exp(\n",
    "            tf.cast(tf.range(num_timescales), tf.float32) * -log_timescale_increment\n",
    "        )\n",
    "        scaled_time = tf.expand_dims(position, 1) * tf.expand_dims(inv_timescales, 0)\n",
    "        position_embeddings = tf.concat(\n",
    "            [tf.sin(scaled_time), tf.cos(scaled_time)], axis=1\n",
    "        )\n",
    "        return inputs + position_embeddings\n",
    "\n",
    "\n",
    "class TransformerBlock(PrunableClusterableLayer):\n",
    "    # TODO: Update docstrings\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(ff_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "                \"ff_dim\": self.ff_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "\n",
    "        # Sublayer 1\n",
    "        attn_output = self.att(inputs)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(\n",
    "            inputs + attn_output\n",
    "        )  # Residual connection, (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        # Sublayer 2\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(\n",
    "            out1 + ffn_output\n",
    "        )  # Residual connection, # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "\n",
    "class T2Model(keras.Model):\n",
    "    # TODO: Update docstrings\n",
    "    \"\"\"Time-Transformer with Multi-headed.\n",
    "    embed_dim --> Embedding size for each token\n",
    "    num_heads --> Number of attention heads\n",
    "    ff_dim    --> Hidden layer size in feed forward network inside transformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        embed_dim,\n",
    "        num_heads,\n",
    "        ff_dim,\n",
    "        num_filters,\n",
    "        num_classes,\n",
    "        num_layers,\n",
    "        droprate,\n",
    "        num_aux_feats=0,\n",
    "        add_aux_feats_to=\"M\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(T2Model, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_filters = num_filters\n",
    "        self.num_layers = num_layers\n",
    "        self.droprate = droprate\n",
    "        self.num_aux_feats = num_aux_feats\n",
    "        self.add_aux_feats_to = add_aux_feats_to\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        if self.add_aux_feats_to == \"L\":\n",
    "            self.sequence_length = input_dim[1] + self.num_aux_feats\n",
    "        else:\n",
    "            self.sequence_length = input_dim[\n",
    "                1\n",
    "            ]  # input_dim.shape = (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        self.embedding = ConvEmbedding(\n",
    "            num_filters=self.num_filters, input_shape=input_dim\n",
    "        )\n",
    "\n",
    "        # <-- Additional layers when adding Z features here -->\n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(\n",
    "            max_steps=self.sequence_length, max_dims=self.embed_dim\n",
    "        )\n",
    "\n",
    "        self.encoder = [\n",
    "            TransformerBlock(self.embed_dim, self.num_heads, self.ff_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "        self.pooling = layers.GlobalAveragePooling1D()\n",
    "        self.dropout1 = layers.Dropout(self.droprate)\n",
    "\n",
    "        # self.fc             = layers.Dense(self.embed_dim, activation=tf.keras.layers.LeakyReLU(alpha=0.01))\n",
    "        # self.dropout2       = layers.Dropout(self.droprate)\n",
    "\n",
    "        self.classifier = layers.Dense(self.num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        # If not a list then inputs are of type tensor: tf.is_tensor(inputs) == True\n",
    "        if tf.is_tensor(inputs):\n",
    "            x = self.embedding(inputs)\n",
    "            x = self.pos_encoding(x)\n",
    "\n",
    "            for layer in self.encoder:\n",
    "                x = layer(x, training)\n",
    "\n",
    "            x = self.pooling(x)\n",
    "            if training:\n",
    "                x = self.dropout1(x, training=training)\n",
    "\n",
    "            # x = self.fc(x)\n",
    "            # if training:\n",
    "            #     x = self.dropout2(x, training=training)\n",
    "\n",
    "            classifier = self.classifier(x)\n",
    "\n",
    "        # if (isinstance(inputs, list)) and (self.add_aux_feats_to == \"M\"):\n",
    "        # Else this implies input is a list; a list of tensors, i.e. multiple inputs\n",
    "        else:\n",
    "            if isinstance(inputs, dict):\n",
    "                x = inputs[\"input_1\"]\n",
    "                z = inputs[\"input_2\"]\n",
    "            else:\n",
    "                # X in L x M\n",
    "                x = inputs[0]\n",
    "                # Additional Z features\n",
    "                z = inputs[1]\n",
    "                # >>> z.shape\n",
    "                # TensorShape([None, 2])\n",
    "            if self.add_aux_feats_to == \"M\":\n",
    "                z = tf.tile(z, [1, 100])\n",
    "                # >>> z.shape\n",
    "                # TensorShape([None, 200])\n",
    "                z = tf.keras.layers.Reshape([100, 2])(z)\n",
    "                # >>> z.shape\n",
    "                # TensorShape([None, 100, 2])\n",
    "                x = tf.keras.layers.Concatenate(axis=2)([x, z])\n",
    "                # >>> x.shape\n",
    "                # TensorShape([None, 100, 8)])\n",
    "            else:  # Else self.add_aux_feats_to == 'L'\n",
    "                z = tf.tile(z, [1, 6])\n",
    "                # >>> z.shape\n",
    "                # TensorShape([None, 12])\n",
    "                z = tf.keras.layers.Reshape([2, 6])(z)\n",
    "                # >>> z.shape\n",
    "                # TensorShape([None, 2, 6])\n",
    "                x = tf.keras.layers.Concatenate(axis=1)([x, z])\n",
    "                # >>> x.shape\n",
    "                # TensorShape([None, 102, 6)])\n",
    "\n",
    "            # Transforms X in L x (M + Z) -> X in L x d if self.add_aux_feats_to == \"M\" or\n",
    "            # transforms X in (L + 2) x M -> X in L x d if self.add_aux_feats_to == \"L\"\n",
    "            x = self.embedding(x)\n",
    "\n",
    "            x = self.pos_encoding(x)  # X <- X + P, where X in L x d\n",
    "\n",
    "            for layer in self.encoder:\n",
    "                x = layer(x, training)\n",
    "\n",
    "            x = self.pooling(x)\n",
    "            if training:\n",
    "                x = self.dropout1(x, training=training)\n",
    "\n",
    "            # Additional layers when adding Z features\n",
    "            # x = tf.keras.layers.Concatenate(axis=1)([inputs[1], x])\n",
    "\n",
    "            # x = self.fc(x)\n",
    "            # if training:\n",
    "            #     x = self.dropout2(x, training=training)\n",
    "\n",
    "            classifier = self.classifier(x)\n",
    "\n",
    "        return classifier\n",
    "    \n",
    "    def model(self):\n",
    "        x = tf.keras.layers.Input(shape=(1500,1))\n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "\n",
    "    def build_graph(self, input_shapes):\n",
    "        if isinstance(\n",
    "            input_shapes, tuple\n",
    "        ):  # A list would imply there is multiple inputs\n",
    "            # Code lifted from example:\n",
    "            # https://github.com/tensorflow/tensorflow/issues/29132#issuecomment-504679288\n",
    "            input_shape_nobatch = input_shapes[1:]\n",
    "            # self.build(input_shapes)\n",
    "            inputs = keras.Input(shape=input_shape_nobatch)\n",
    "        else:\n",
    "            input_shape_nobatch = input_shapes[0][1:]\n",
    "            Z_input_shape_nobatch = input_shapes[1][1:]\n",
    "            inputs = [\n",
    "                tf.keras.Input(shape=input_shape_nobatch),\n",
    "                tf.keras.Input(shape=Z_input_shape_nobatch),\n",
    "            ]\n",
    "\n",
    "        if not hasattr(self, \"call\"):\n",
    "            raise AttributeError(\"User should define 'call' method in sub-class model!\")\n",
    "\n",
    "        _ = self.call(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f41c949-765a-4a72-b6c6-d8b0df9fd90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import pickle\n",
    "with open(\"../preproccessed_data.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "train = data['train']\n",
    "train_target = data['train_target']\n",
    "validation = data['validation']\n",
    "validation_target = data['validation_target']\n",
    "test = data['test']\n",
    "test_target = data['test_target']\n",
    "\n",
    "# search with a subset of the data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train, _, train_target, _ = train_test_split(train, train_target, test_size=0.8, stratify=train_target, random_state=0)\n",
    "# validation, _, validation_target, _ = train_test_split(validation, validation_target, test_size=0.8, stratify=validation_target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195afefa-1107-4513-8c5b-c31cd00ebc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 23:49:57.451447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30873 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "model = T2Model(input_dim=(1500,1),\n",
    "embed_dim=6,\n",
    "num_heads=3,\n",
    "ff_dim=10,\n",
    "num_filters=6,\n",
    "num_classes=4,\n",
    "num_layers=3,\n",
    "droprate=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3cff4e-6dc8-4a4c-81a6-bbb460aedc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model = model.model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b2f9cd6-1c7b-45d9-89b8-f83b96346715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1500, 1)]         0         \n",
      "                                                                 \n",
      " conv_embedding (ConvEmbeddi  (None, 1500, 6)          12        \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " positional_encoding (Positi  (None, 1500, 6)          0         \n",
      " onalEncoding)                                                   \n",
      "                                                                 \n",
      " transformer_block (Transfor  (None, 1500, 6)          328       \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " transformer_block_1 (Transf  (None, 1500, 6)          328       \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_2 (Transf  (None, 1500, 6)          328       \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 6)                0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 4)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,024\n",
      "Trainable params: 1,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "func_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898332dd-fee2-42fe-a8ee-ade96953943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# print(\"model parameters: \" , model.count_params()/1000)\n",
    "# print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e2afe-426c-4736-b927-5f91e38ee06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 23:50:31.587750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-14 23:50:32.434637: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-14 23:50:32.435741: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-14 23:50:32.436030: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-07-14 23:50:32.439331: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-14 23:50:32.439412: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:317] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-07-14 23:50:32.691959: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x2af06c0c0a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-14 23:50:32.692027: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-07-14 23:50:32.704352: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-14 23:50:32.875975: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-14 23:50:32.995044: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485/1485 [==============================] - 597s 391ms/step - loss: 1.3082 - accuracy: 0.3636 - val_loss: 1.4863 - val_accuracy: 0.3645\n",
      "Epoch 2/200\n",
      "1485/1485 [==============================] - 577s 389ms/step - loss: 1.2473 - accuracy: 0.4160 - val_loss: 1.4659 - val_accuracy: 0.3921\n",
      "Epoch 3/200\n",
      " 123/1485 [=>............................] - ETA: 8:39 - loss: 1.2293 - accuracy: 0.4289"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# chk = ModelCheckpoint(model_name, monitor='val_accuracy', save_best_only=True, mode='max', verbose=2)\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=100)\n",
    "model.fit(train, train_target, epochs=200, batch_size=128, callbacks=[es], validation_data=(validation,validation_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0245b6-5631-4e57-8053-946bb1c05a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
