{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad0c229-36c1-451b-a99f-9f962a7c5012",
   "metadata": {},
   "source": [
    "### Performance on Bauch test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0ee39a-0d46-498c-84fa-08570e5d430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "# load the data\n",
    "with open(\"preproccessed_data_uncensored.pickle\", \"rb\") as f:\n",
    "    data_dic = pickle.load(f)\n",
    "\n",
    "test = data_dic['test']\n",
    "test_target = data_dic['test_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d406f6b4-8301-48e5-844e-f8d341b0f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test)\n",
    "test_target = np.array(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63915ce8-9cb3-4f0b-8e4f-30d52346a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = [t>1 for t in test_target]\n",
    "test = test[filter_list]\n",
    "test_target = test_target[filter_list]\n",
    "\n",
    "test_target[test_target == 3] = 0\n",
    "test_target[test_target == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a320003-f52d-4ea2-a18c-6d667592adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"amit_apply_bauch_test_uncencored.pickle\", \"rb\") as f:\n",
    "    amit_pred = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847d3929-6f5c-41e6-a50d-83d4e93585aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "amit_pred = np.array(amit_pred)\n",
    "amit_pred = amit_pred[filter_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41479dc8-9af7-45ad-8b75-8da3900f04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = amit_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0834521-ca48-4faf-8922-d2b3d8fea41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.444     0.008     0.016       500\n",
      "           1      0.499     0.990     0.664       500\n",
      "\n",
      "    accuracy                          0.499      1000\n",
      "   macro avg      0.472     0.499     0.340      1000\n",
      "weighted avg      0.472     0.499     0.340      1000\n",
      "\n",
      "F1 score: 0.33985049787922034\n",
      "Precision:  0.4719699517883171\n",
      "Recall:  0.499\n",
      "Confusion matrix: \n",
      " [[  4 496]\n",
      " [  5 495]]\n"
     ]
    }
   ],
   "source": [
    "#performance on bauch uncensored\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_preds = np.argmax(test_preds, axis=2)\n",
    "print(\"accuracy: \", accuracy_score(test_target, test_preds))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(classification_report(test_target, test_preds, digits=3))\n",
    "print(\"F1 score:\",f1_score(test_target, test_preds, average='macro'))\n",
    "print(\"Precision: \",precision_score(test_target, test_preds, average=\"macro\"))\n",
    "print(\"Recall: \",recall_score(test_target, test_preds, average=\"macro\"))    \n",
    "print(\"Confusion matrix: \\n\",confusion_matrix(test_target, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2744f0aa-1158-494e-a773-5c769d161a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "# load the data\n",
    "with open(\"preproccessed_data.pickle\", \"rb\") as f:\n",
    "    data_dic = pickle.load(f)\n",
    "\n",
    "test = data_dic['test']\n",
    "test_target = data_dic['test_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdb0e079-c60c-45b4-b82f-817e098c0879",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test)\n",
    "test_target = np.array(test_target)\n",
    "\n",
    "filter_list = [t>1 for t in test_target]\n",
    "test = test[filter_list]\n",
    "test_target = test_target[filter_list]\n",
    "\n",
    "test_target[test_target == 3] = 0\n",
    "test_target[test_target == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f9bf81c-8bc8-4556-9b71-bf3722c7a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"amit_apply_bauch_test_cencored.pickle\", \"rb\") as f:\n",
    "    amit_pred = pickle.load(f)\n",
    "\n",
    "amit_pred = np.array(amit_pred)\n",
    "amit_pred = amit_pred[filter_list]\n",
    "test_preds = amit_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9336fcc7-0ede-4f4c-ae58-cb2a3da5efdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.824     0.028     0.054       500\n",
      "           1      0.506     0.994     0.670       500\n",
      "\n",
      "    accuracy                          0.511      1000\n",
      "   macro avg      0.665     0.511     0.362      1000\n",
      "weighted avg      0.665     0.511     0.362      1000\n",
      "\n",
      "F1 score: 0.36221079389757027\n",
      "Precision:  0.6645622643767578\n",
      "Recall:  0.511\n",
      "Confusion matrix: \n",
      " [[ 14 486]\n",
      " [  3 497]]\n"
     ]
    }
   ],
   "source": [
    "#performance on bauch uncensored\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_preds = np.argmax(test_preds, axis=2)\n",
    "print(\"accuracy: \", accuracy_score(test_target, test_preds))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(classification_report(test_target, test_preds, digits=3))\n",
    "print(\"F1 score:\",f1_score(test_target, test_preds, average='macro'))\n",
    "print(\"Precision: \",precision_score(test_target, test_preds, average=\"macro\"))\n",
    "print(\"Recall: \",recall_score(test_target, test_preds, average=\"macro\"))    \n",
    "print(\"Confusion matrix: \\n\",confusion_matrix(test_target, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1177e-d5e1-4cca-88a0-3e12221b3d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35fb8e-ac4a-4274-bdeb-d1d797f606d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0717d284-c169-49af-9c6d-7957cdfe3314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af359694-f57a-4342-980b-0757fce9be09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd2d84b7-80e8-4cdf-a1df-4aa3af3361a9",
   "metadata": {},
   "source": [
    "### Performance on noise induced test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4629313e-d43b-457e-bf6c-25f203d2f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"train_amit/envn_uncen_resids_dic.pickle\", \"rb\") as f:\n",
    "    data_dic_t1 = pickle.load(f)\n",
    "\n",
    "with open(\"train_amit/whiten_uncen_resids_dic.pickle\", \"rb\") as f:\n",
    "    data_dic_t2 = pickle.load(f)\n",
    "\n",
    "with open(\"train_amit/demn_uncen_resids_dic.pickle\", \"rb\") as f:\n",
    "    data_dic_t3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bda34ca-8732-40bb-b43f-17651b866aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_envn = data_dic_t1['test']\n",
    "test_envn_target = data_dic_t1['test_target']\n",
    "test_whiten = data_dic_t2['test']\n",
    "test_whiten_target = data_dic_t2['test_target']\n",
    "test_demn = data_dic_t3['test']\n",
    "test_demn_target = data_dic_t3['test_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbbda954-9344-41e7-b574-9446cc02c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"amit_apply_test_demn.pickle\", \"rb\") as f:\n",
    "    preds_demn = pickle.load(f)\n",
    "\n",
    "with open(\"amit_apply_test_whiten.pickle\", \"rb\") as f:\n",
    "    preds_whiten = pickle.load(f)\n",
    "\n",
    "with open(\"amit_apply_test_envn.pickle\", \"rb\") as f:\n",
    "    preds_envn = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7aac884-b165-42fe-80fa-6eed4c4fc2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Env noise\n",
      "envn test accuracy:  0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.988     0.990       500\n",
      "           1      0.988     0.992     0.990       500\n",
      "\n",
      "    accuracy                          0.990      1000\n",
      "   macro avg      0.990     0.990     0.990      1000\n",
      "weighted avg      0.990     0.990     0.990      1000\n",
      "\n",
      "envn F1 score: 0.98999995999984\n",
      "envn Precision:  0.990007840125442\n",
      "envn Recall:  0.99\n",
      "envn Confusion matrix: \n",
      " [[494   6]\n",
      " [  4 496]]\n",
      "############### Dem noise\n",
      "demn test accuracy:  0.995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.990     0.995       500\n",
      "           1      0.990     1.000     0.995       500\n",
      "\n",
      "    accuracy                          0.995      1000\n",
      "   macro avg      0.995     0.995     0.995      1000\n",
      "weighted avg      0.995     0.995     0.995      1000\n",
      "\n",
      "envn F1 score: 0.9949998749968749\n",
      "envn Precision:  0.995049504950495\n",
      "envn Recall:  0.995\n",
      "envn Confusion matrix: \n",
      " [[495   5]\n",
      " [  0 500]]\n",
      "############### White noise\n",
      "whiten test accuracy:  0.967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.998     0.936     0.966       500\n",
      "           1      0.940     0.998     0.968       500\n",
      "\n",
      "    accuracy                          0.967      1000\n",
      "   macro avg      0.969     0.967     0.967      1000\n",
      "weighted avg      0.969     0.967     0.967      1000\n",
      "\n",
      "whiten F1 score: 0.9669682564944913\n",
      "whiten Precision:  0.9688020751769804\n",
      "whiten Recall:  0.9670000000000001\n",
      "whiten Confusion matrix: \n",
      " [[468  32]\n",
      " [  1 499]]\n"
     ]
    }
   ],
   "source": [
    "# uncensored prerofmance\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "test_demn_preds = np.argmax(preds_demn, axis=2)\n",
    "test_whiten_preds = np.argmax(preds_whiten, axis=2)\n",
    "test_envn_preds = np.argmax(preds_envn, axis=2)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(\"############### Env noise\")\n",
    "print(\"envn test accuracy: \", accuracy_score(test_envn_target, test_envn_preds))\n",
    "print(classification_report(test_envn_target, test_envn_preds, digits=3))\n",
    "print(\"envn F1 score:\",f1_score(test_envn_target, test_envn_preds, average='macro'))\n",
    "print(\"envn Precision: \",precision_score(test_envn_target, test_envn_preds, average=\"macro\"))\n",
    "print(\"envn Recall: \",recall_score(test_envn_target, test_envn_preds, average=\"macro\"))    \n",
    "print(\"envn Confusion matrix: \\n\",confusion_matrix(test_envn_target, test_envn_preds))\n",
    "\n",
    "print(\"############### Dem noise\")\n",
    "print(\"demn test accuracy: \", accuracy_score(test_demn_target, test_demn_preds))\n",
    "print(classification_report(test_demn_target, test_demn_preds, digits=3))\n",
    "print(\"envn F1 score:\",f1_score(test_demn_target, test_demn_preds, average='macro'))\n",
    "print(\"envn Precision: \",precision_score(test_demn_target, test_demn_preds, average=\"macro\"))\n",
    "print(\"envn Recall: \",recall_score(test_demn_target, test_demn_preds, average=\"macro\"))    \n",
    "print(\"envn Confusion matrix: \\n\",confusion_matrix(test_demn_target, test_demn_preds))\n",
    "\n",
    "print(\"############### White noise\")\n",
    "print(\"whiten test accuracy: \", accuracy_score(test_whiten_target, test_whiten_preds))\n",
    "print(classification_report(test_whiten_target, test_whiten_preds, digits=3))\n",
    "print(\"whiten F1 score:\",f1_score(test_whiten_target, test_whiten_preds, average='macro'))\n",
    "print(\"whiten Precision: \",precision_score(test_whiten_target, test_whiten_preds, average=\"macro\"))\n",
    "print(\"whiten Recall: \",recall_score(test_whiten_target, test_whiten_preds, average=\"macro\"))    \n",
    "print(\"whiten Confusion matrix: \\n\",confusion_matrix(test_whiten_target, test_whiten_preds))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514c2929-45b9-457e-9541-764bef735c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Env noise\n",
      "envn test accuracy:  0.536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.072     0.134       500\n",
      "           1      0.519     1.000     0.683       500\n",
      "\n",
      "    accuracy                          0.536      1000\n",
      "   macro avg      0.759     0.536     0.409      1000\n",
      "weighted avg      0.759     0.536     0.409      1000\n",
      "\n",
      "envn F1 score: 0.4086942337492864\n",
      "envn Precision:  0.7593360995850622\n",
      "envn Recall:  0.536\n",
      "envn Confusion matrix: \n",
      " [[ 36 464]\n",
      " [  0 500]]\n",
      "############### Dem noise\n",
      "demn test accuracy:  0.545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.090     0.165       500\n",
      "           1      0.524     1.000     0.687       500\n",
      "\n",
      "    accuracy                          0.545      1000\n",
      "   macro avg      0.762     0.545     0.426      1000\n",
      "weighted avg      0.762     0.545     0.426      1000\n",
      "\n",
      "envn F1 score: 0.42621141902329834\n",
      "envn Precision:  0.7617801047120418\n",
      "envn Recall:  0.545\n",
      "envn Confusion matrix: \n",
      " [[ 45 455]\n",
      " [  0 500]]\n",
      "############### White noise\n",
      "whiten test accuracy:  0.562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.124     0.221       500\n",
      "           1      0.533     1.000     0.695       500\n",
      "\n",
      "    accuracy                          0.562      1000\n",
      "   macro avg      0.767     0.562     0.458      1000\n",
      "weighted avg      0.767     0.562     0.458      1000\n",
      "\n",
      "whiten F1 score: 0.45802543073367025\n",
      "whiten Precision:  0.7665245202558635\n",
      "whiten Recall:  0.562\n",
      "whiten Confusion matrix: \n",
      " [[ 62 438]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "#censored performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_demn_preds = np.argmax(preds_demn, axis=2)\n",
    "test_whiten_preds = np.argmax(preds_whiten, axis=2)\n",
    "test_envn_preds = np.argmax(preds_envn, axis=2)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(\"############### Env noise\")\n",
    "print(\"envn test accuracy: \", accuracy_score(test_envn_target, test_envn_preds))\n",
    "print(classification_report(test_envn_target, test_envn_preds, digits=3))\n",
    "print(\"envn F1 score:\",f1_score(test_envn_target, test_envn_preds, average='macro'))\n",
    "print(\"envn Precision: \",precision_score(test_envn_target, test_envn_preds, average=\"macro\"))\n",
    "print(\"envn Recall: \",recall_score(test_envn_target, test_envn_preds, average=\"macro\"))    \n",
    "print(\"envn Confusion matrix: \\n\",confusion_matrix(test_envn_target, test_envn_preds))\n",
    "\n",
    "print(\"############### Dem noise\")\n",
    "print(\"demn test accuracy: \", accuracy_score(test_demn_target, test_demn_preds))\n",
    "print(classification_report(test_demn_target, test_demn_preds, digits=3))\n",
    "print(\"envn F1 score:\",f1_score(test_demn_target, test_demn_preds, average='macro'))\n",
    "print(\"envn Precision: \",precision_score(test_demn_target, test_demn_preds, average=\"macro\"))\n",
    "print(\"envn Recall: \",recall_score(test_demn_target, test_demn_preds, average=\"macro\"))    \n",
    "print(\"envn Confusion matrix: \\n\",confusion_matrix(test_demn_target, test_demn_preds))\n",
    "\n",
    "print(\"############### White noise\")\n",
    "print(\"whiten test accuracy: \", accuracy_score(test_whiten_target, test_whiten_preds))\n",
    "print(classification_report(test_whiten_target, test_whiten_preds, digits=3))\n",
    "print(\"whiten F1 score:\",f1_score(test_whiten_target, test_whiten_preds, average='macro'))\n",
    "print(\"whiten Precision: \",precision_score(test_whiten_target, test_whiten_preds, average=\"macro\"))\n",
    "print(\"whiten Recall: \",recall_score(test_whiten_target, test_whiten_preds, average=\"macro\"))    \n",
    "print(\"whiten Confusion matrix: \\n\",confusion_matrix(test_whiten_target, test_whiten_preds))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de49e3-5d06-4aec-a60c-67a2ae65bbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf563f-721e-4b5f-9fe5-c08f1483830b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735783f-2ff5-4267-86a7-6a63a4e074c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
